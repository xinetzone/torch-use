
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>å¿«é€Ÿå…¥é—¨ &#8212; torch-book 0.0.1 æ–‡æ¡£</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/default.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/tabs.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "xinetzone/torch-book");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "ğŸ’¬ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../_static/translations.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="canonical" href="https://xinetzone.github.io/torch-book/quant/start.html" />
    <link rel="shortcut icon" href="../_static/favicon.jpg"/>
    <link rel="index" title="ç´¢å¼•" href="../genindex.html" />
    <link rel="search" title="æœç´¢" href="../search.html" />
    <link rel="next" title="MMDetection" href="../openmmlab/index.html" />
    <link rel="prev" title="é‡åŒ–ç®€ä»‹" href="intro.html" /> 
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="zh_CN">
    

    <!-- Google Analytics -->
     
<link
  rel="alternate"
  type="application/atom+xml"
  href="../posts/atom.xml"
  title="Blog"
/>
 
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.jpg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   é¡¹ç›®ç®€ä»‹
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../tutorials/index.html">
   æ•™ç¨‹
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../tutorials/basics/index.html">
     PyTorch åŸºç¡€
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorials/basics/quickstart.html">
       å¿«é€Ÿå…¥é—¨
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorials/basics/autogradqs.html">
       è‡ªåŠ¨å¾®åˆ†
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../tutorials/object-detection/index.html">
     ç›®æ ‡æ£€æµ‹
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../tutorials/object-detection/yolo/index.html">
       YOLO ç³»åˆ—
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
      <label for="toctree-checkbox-4">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../tutorials/object-detection/yolo/intro.html">
         YOLO ç®€ä»‹
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../tutorials/object-detection/yolo/tutorials/index.html">
         YOLO æ•™ç¨‹
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../tutorials/notes/index.html">
     ç¬”è®°
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorials/notes/autograd-mechanics.html">
       è‡ªåŠ¨å¾®åˆ†æœºåˆ¶
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorials/notes/detection.html">
       ç›®æ ‡æ£€æµ‹
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorials/notes/extending.html">
       æ‰©å±• PyTorch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../tutorials/notes/thop.html">
       THOP: PyTorch OpCounter
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/seg-fine-tuning.html">
     å¾®è°ƒåˆ†å‰²
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   é‡åŒ–
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="intro.html">
     é‡åŒ–ç®€ä»‹
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     å¿«é€Ÿå…¥é—¨
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../openmmlab/index.html">
   MMDetection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../openmmlab/start.html">
     MMDect å¿«é€Ÿä¸Šæ‰‹
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chaos/index.html">
   Eager é‡åŒ–(æ··ä¹±)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chaos/intro.html">
     é‡åŒ–ç®€ä»‹ï¼ˆEagerï¼‰
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chaos/recipes.html">
     é‡åŒ–èœè°±
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chaos/quantized-tensor.html">
     é‡åŒ–å¼ é‡
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../chaos/start/index.html">
     å¿«é€Ÿä¸Šæ‰‹
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/start/basic.html">
       åŸºç¡€
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/start/ns.html">
       Pytorch æ•°å€¼å¥—ä»¶æ•™ç¨‹
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../chaos/study/index.html">
     å­¦ä¹ 
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/study/intro.html">
       æ¦‚è¿°
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../chaos/study/transfer-learning/index.html">
       è¿ç§»å­¦ä¹ 
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
      <label for="toctree-checkbox-11">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../chaos/study/transfer-learning/basic.html">
         è®¡ç®—æœºè§†è§‰åˆ†ç±»
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../chaos/study/transfer-learning/quantized.html">
         é‡åŒ–è®¡ç®—æœºè§†è§‰åˆ†ç±»
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../chaos/study/transfer-learning/custom.html">
         è‡ªå®šä¹‰
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../chaos/study/transfer-learning/cifar.html">
         æµ‹è¯•
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../chaos/study/transfer-learning/tvm.html">
         TVM
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../chaos/study/advanced/index.html">
       é«˜çº§æ•™ç¨‹
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
      <label for="toctree-checkbox-12">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../chaos/study/advanced/custom.html">
         è‡ªå®šä¹‰é‡åŒ–
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../chaos/study/advanced/run.html">
         é€šç”¨é‡åŒ–æ¨¡å‹
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../chaos/study/advanced/qat.html">
         QAT
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../chaos/study/advanced/cifar.html">
         ç‰¹å®šäº cifar10 çš„é‡åŒ–ï¼ˆå¾…æ›´ï¼‰
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/study/qat-resnet18.html">
       QATï¼ˆresnet18ï¼‰
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/study/test.html">
       æµ‹è¯• QAT
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/study/draft.html">
       å›æ”¶ç«™
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../chaos/tutorial/index.html">
     æ•™ç¨‹
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/tutorial/pqt-qat.html">
       PTQ ä¸ QAT å®è·µ
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/tutorial/qat.html">
       QAT çš„ä¸åŒè®­ç»ƒç­–ç•¥
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/tutorial/qat-fuse.html">
       QAT çš„ä¸åŒè®­ç»ƒç­–ç•¥
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/tutorial/tvm.html">
       TVM åˆæ¢
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../chaos/papers/index.html">
     è®ºæ–‡
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../chaos/papers/gholami2021survey.html">
       A Survey of Quantization Methods for Efficient Neural Network Inference
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ecosystem/index.html">
   ç”Ÿæ€ç³»ç»Ÿ
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ecosystem/intro.html">
     ç®€ä»‹
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../others/index.html">
   å…¶ä»–
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../others/colab.html">
     Colab è®­ç»ƒ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../others/en-zh.html">
     ä¸­è‹±äº’è¯‘
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../others/raw.html">
     æœªæ•´ç†çš„èµ„æ–™
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../refs.html">
   å‚è€ƒ
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../glossary/index.html">
   æœ¯è¯­è¡¨
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../glossary/numpy.html">
     NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../glossary/pytorch.html">
     PyTorch è¯æ±‡è¡¨
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            <div>
ç‰ˆæƒæ‰€æœ‰Â Â©Â 2021 <a href="https://xinetzone.github.io/">xinetzone</a></div>
<div>ç”± <a href="https://ebp.jupyterbook.org/">EBP</a> æä¾›æŠ€æœ¯æ”¯æŒ</div>
<a href="https://torch-book.readthedocs.io/">ç‰ˆæœ¬åˆ‡æ¢</a>

            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/xinetzone/torch-book/main?urlpath=lab/tree/docs/quant/start.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/xinetzone/torch-book/blob/main/docs/quant/start.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/xinetzone/torch-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/xinetzone/torch-book/issues/new?title=Issue%20on%20page%20%2Fquant/start.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/xinetzone/torch-book/edit/main/docs/quant/start.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/quant/start.ipynb.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> å¯¼èˆª
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fx-graph">
   FX Graph æ¨¡å¼é‡åŒ–çš„åŠ¨æœº
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prepare-dataset">
   å®šä¹‰è¾…åŠ©å‡½æ•°å’Œ Prepare Dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   è¯„ä¼°æ¨¡å¼çš„æ¨¡å‹
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#qconfig-dict">
   ä½¿ç”¨
   <code class="docutils literal notranslate">
    <span class="pre">
     qconfig_dict
    </span>
   </code>
   æŒ‡å®šå¦‚ä½•é‡åŒ–æ¨¡å‹
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   ä¸ºé™æ€åè®­ç»ƒé‡åŒ–æ¨¡å‹åšå‡†å¤‡
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   æ ¡å‡†
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   å°†æ¨¡å‹è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   è¯„ä¼°
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   è°ƒè¯•é‡åŒ–æ¨¡å‹
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#eager">
   åŸºçº¿æµ®ç‚¹æ¨¡å‹å’Œ Eager æ¨¡å¼é‡åŒ–çš„æ¯”è¾ƒ
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>å¿«é€Ÿå…¥é—¨</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> å¯¼èˆª </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fx-graph">
   FX Graph æ¨¡å¼é‡åŒ–çš„åŠ¨æœº
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prepare-dataset">
   å®šä¹‰è¾…åŠ©å‡½æ•°å’Œ Prepare Dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   è¯„ä¼°æ¨¡å¼çš„æ¨¡å‹
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#qconfig-dict">
   ä½¿ç”¨
   <code class="docutils literal notranslate">
    <span class="pre">
     qconfig_dict
    </span>
   </code>
   æŒ‡å®šå¦‚ä½•é‡åŒ–æ¨¡å‹
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   ä¸ºé™æ€åè®­ç»ƒé‡åŒ–æ¨¡å‹åšå‡†å¤‡
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   æ ¡å‡†
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   å°†æ¨¡å‹è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   è¯„ä¼°
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   è°ƒè¯•é‡åŒ–æ¨¡å‹
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#eager">
   åŸºçº¿æµ®ç‚¹æ¨¡å‹å’Œ Eager æ¨¡å¼é‡åŒ–çš„æ¯”è¾ƒ
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                 <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>å¿«é€Ÿå…¥é—¨<a class="headerlink" href="#id1" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h1>
<p>å‚è€ƒï¼š</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://pytorch.org/blog/quantization-in-practice/">é‡åŒ–å®è·µ</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/tutorials/prototype/fx_graph_mode_ptq_static.html">fx graph æ¨¡å¼ POST TRAINING STATIC QUANTIZATION</a></p></li>
</ol>
<p>æœ¬æ•™ç¨‹ä»‹ç»åŸºäº <a class="reference external" href="https://pytorch.org/docs/stable/fx.html#module-torch.fx" title="(åœ¨ PyTorch v1.12)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.fx</span></code></a> åœ¨ graph æ¨¡å¼ä¸‹è¿›è¡Œè®­ç»ƒåé™æ€é‡åŒ–çš„æ­¥éª¤ã€‚FX Graph æ¨¡å¼é‡åŒ–çš„ä¼˜ç‚¹ï¼šå¯ä»¥åœ¨æ¨¡å‹ä¸Šå®Œå…¨è‡ªåŠ¨åœ°æ‰§è¡Œé‡åŒ–ï¼Œå°½ç®¡å¯èƒ½éœ€è¦ä¸€äº›åŠªåŠ›ä½¿æ¨¡å‹ä¸ FX Graph æ¨¡å¼é‡åŒ–å…¼å®¹ï¼ˆè±¡å¾æ€§åœ°ç”¨ <a class="reference external" href="https://pytorch.org/docs/stable/fx.html#module-torch.fx" title="(åœ¨ PyTorch v1.12)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.fx</span></code></a> è·Ÿè¸ªï¼‰ï¼Œå°†æœ‰å•ç‹¬çš„æ•™ç¨‹æ¥å±•ç¤ºå¦‚ä½•ä½¿æˆ‘ä»¬æƒ³é‡åŒ–çš„æ¨¡å‹çš„ä¸€éƒ¨åˆ†ä¸ FX Graph æ¨¡å¼é‡åŒ–å…¼å®¹ã€‚ä¹Ÿæœ‰ <a class="reference external" href="https://pytorch.org/tutorials/prototype/fx_graph_mode_ptq_dynamic.html">FX Graph æ¨¡å¼åè®­ç»ƒåŠ¨æ€é‡åŒ–</a> æ•™ç¨‹ã€‚FX Graph æ¨¡å¼ API å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.quantization</span> <span class="kn">import</span> <span class="n">get_default_qconfig</span>
<span class="c1"># Note that this is temporary, </span>
<span class="c1"># we&#39;ll expose these functions to torch.quantization after official releasee</span>
<span class="kn">from</span> <span class="nn">torch.quantization.quantize_fx</span> <span class="kn">import</span> <span class="n">prepare_fx</span><span class="p">,</span> <span class="n">convert_fx</span>
<span class="n">float_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">qconfig</span> <span class="o">=</span> <span class="n">get_default_qconfig</span><span class="p">(</span><span class="s2">&quot;fbgemm&quot;</span><span class="p">)</span>
<span class="n">qconfig_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;&quot;</span><span class="p">:</span> <span class="n">qconfig</span><span class="p">}</span>
<span class="k">def</span> <span class="nf">calibrate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">image</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">prepared_model</span> <span class="o">=</span> <span class="n">prepare_fx</span><span class="p">(</span><span class="n">float_model</span><span class="p">,</span> <span class="n">qconfig_dict</span><span class="p">)</span>  <span class="c1"># fuse modules and insert observers</span>
<span class="n">calibrate</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">,</span> <span class="n">valset</span><span class="p">)</span>  <span class="c1"># run calibration on sample data</span>
<span class="n">quantized_model</span> <span class="o">=</span> <span class="n">convert_fx</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">)</span>  <span class="c1"># convert the calibrated model to a quantized model</span>
</pre></div>
</div>
<section id="fx-graph">
<h2>FX Graph æ¨¡å¼é‡åŒ–çš„åŠ¨æœº<a class="headerlink" href="#fx-graph" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h2>
<p>ç›®å‰ PyTorch å­˜åœ¨ eager æ¨¡å¼é‡åŒ–ï¼š<a class="reference external" href="https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html">Static Quantization with Eager Mode in PyTorch</a>ã€‚</p>
<p>å¯ä»¥çœ‹åˆ°ï¼Œè¯¥è¿‡ç¨‹æ¶‰åŠåˆ°å¤šä¸ªæ‰‹åŠ¨æ­¥éª¤ï¼ŒåŒ…æ‹¬ï¼š</p>
<ul class="simple">
<li><p>æ˜¾å¼åœ° quantize å’Œ dequantize activationsï¼Œå½“æµ®ç‚¹å’Œé‡åŒ–è¿ç®—æ··åˆåœ¨æ¨¡å‹ä¸­æ—¶ï¼Œè¿™æ˜¯éå¸¸è€—æ—¶çš„ã€‚</p></li>
<li><p>æ˜¾å¼èåˆæ¨¡å—ï¼Œè¿™éœ€è¦æ‰‹åŠ¨è¯†åˆ«å·ç§¯åºåˆ—ã€ batch norms ä»¥åŠ relus å’Œå…¶ä»–èåˆæ¨¡å¼ã€‚</p></li>
<li><p>PyTorch å¼ é‡è¿ç®—éœ€è¦ç‰¹æ®Šå¤„ç†ï¼ˆå¦‚ <code class="docutils literal notranslate"><span class="pre">add</span></code>ã€<code class="docutils literal notranslate"><span class="pre">concat</span></code> ç­‰ï¼‰ã€‚</p></li>
<li><p>å‡½æ•°å¼æ²¡æœ‰  first class æ”¯æŒï¼ˆ<code class="docutils literal notranslate"><span class="pre">functional.conv2d</span></code> å’Œ <code class="docutils literal notranslate"><span class="pre">functional.linear</span></code> ä¸ä¼šè¢«é‡åŒ–ï¼‰</p></li>
</ul>
<p>è¿™äº›éœ€è¦çš„ä¿®æ”¹å¤§å¤šæ¥è‡ªäº Eager æ¨¡å¼é‡åŒ–çš„æ½œåœ¨é™åˆ¶ã€‚Eager æ¨¡å¼åœ¨æ¨¡å—çº§å·¥ä½œï¼Œå› ä¸ºå®ƒä¸èƒ½æ£€æŸ¥å®é™…è¿è¡Œçš„ä»£ç ï¼ˆåœ¨ <code class="docutils literal notranslate"><span class="pre">forward</span></code> å‡½æ•°ä¸­ï¼‰ï¼Œé‡åŒ–æ˜¯é€šè¿‡æ¨¡å—äº¤æ¢å®ç°çš„ï¼Œä¸çŸ¥é“åœ¨ Eager æ¨¡å¼ä¸‹ <code class="docutils literal notranslate"><span class="pre">forward</span></code> å‡½æ•°ä¸­æ¨¡å—æ˜¯å¦‚ä½•ä½¿ç”¨çš„ã€‚å› æ­¤ï¼Œå®ƒéœ€è¦ç”¨æˆ·æ‰‹åŠ¨æ’å…¥ <code class="docutils literal notranslate"><span class="pre">QuantStub</span></code> å’Œ <code class="docutils literal notranslate"><span class="pre">DeQuantStub</span></code>ï¼Œä»¥æ ‡è®°ä»–ä»¬æƒ³è¦ quantize æˆ– dequantize çš„ç‚¹ã€‚åœ¨å›¾æ¨¡å¼ä¸­ï¼Œå¯ä»¥æ£€æŸ¥åœ¨ <code class="docutils literal notranslate"><span class="pre">forward</span></code> å‡½æ•°ä¸­æ‰§è¡Œçš„å®é™…ä»£ç ï¼ˆä¾‹å¦‚ <code class="docutils literal notranslate"><span class="pre">aten</span></code> å‡½æ•°è°ƒç”¨ï¼‰ï¼Œé‡åŒ–æ˜¯é€šè¿‡æ¨¡å—å’Œ graph æ“ä½œå®ç°çš„ã€‚ç”±äºå›¾æ¨¡å¼å¯¹è¿è¡Œçš„ä»£ç å…·æœ‰å®Œå…¨çš„å¯è§æ€§ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åœ°æ‰¾å‡ºè¦èåˆå“ªäº›æ¨¡å—ï¼Œåœ¨å“ªé‡Œæ’å…¥ observer è°ƒç”¨ï¼Œquantize/dequantize å‡½æ•°ç­‰ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åŒ–æ•´ä¸ªé‡åŒ–è¿‡ç¨‹ã€‚</p>
<p>FX Graph æ¨¡å¼é‡åŒ–çš„ä¼˜ç‚¹æ˜¯ï¼š</p>
<ul class="simple">
<li><p>ç®€åŒ–é‡åŒ–æµç¨‹ï¼Œæœ€å°åŒ–æ‰‹åŠ¨æ­¥éª¤</p></li>
<li><p>å¼€å¯äº†è¿›è¡Œæ›´é«˜çº§åˆ«ä¼˜åŒ–çš„å¯èƒ½æ€§ï¼Œå¦‚è‡ªåŠ¨ç²¾åº¦é€‰æ‹©ï¼ˆautomatic precision selectionï¼‰</p></li>
</ul>
</section>
<section id="prepare-dataset">
<h2>å®šä¹‰è¾…åŠ©å‡½æ•°å’Œ Prepare Dataset<a class="headerlink" href="#prepare-dataset" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h2>
<p>é¦–å…ˆè¿›è¡Œå¿…è¦çš„å¯¼å…¥ï¼Œå®šä¹‰ä¸€äº›è¾…åŠ©å‡½æ•°å¹¶å‡†å¤‡æ•°æ®ã€‚è¿™äº›æ­¥éª¤ä¸ PyTorch ä¸­ <a class="reference external" href="https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html">ä½¿ç”¨ Eager æ¨¡å¼çš„é™æ€é‡åŒ–</a> ç›¸åŒã€‚</p>
<p>è¦ä½¿ç”¨æ•´ä¸ª ImageNet æ•°æ®é›†è¿è¡Œæœ¬æ•™ç¨‹ä¸­çš„ä»£ç ï¼Œé¦–å…ˆæŒ‰ç…§ <a class="reference external" href="http://www.image-net.org/download">ImageNet Data</a> ä¸­çš„è¯´æ˜ä¸‹è½½ ImageNetã€‚å°†ä¸‹è½½çš„æ–‡ä»¶è§£å‹ç¼©åˆ° <code class="docutils literal notranslate"><span class="pre">data_path</span></code> æ–‡ä»¶å¤¹ä¸­ã€‚</p>
<p>ä¸‹è½½ <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision</span> <span class="pre">resnet18</span> <span class="pre">æ¨¡å‹</span></code> å¹¶å°†å…¶é‡å‘½åä¸º <code class="docutils literal notranslate"><span class="pre">models/resnet18_pretrained_float.pth</span></code>ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_book.data</span> <span class="kn">import</span> <span class="n">ImageNet</span>


<span class="n">root</span> <span class="o">=</span> <span class="s2">&quot;/media/pc/data/4tb/lxw/datasets/ILSVRC&quot;</span>
<span class="n">saved_model_dir</span> <span class="o">=</span> <span class="s1">&#39;models/&#39;</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ImageNet</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>
<span class="n">trainset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="n">valset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;resnet18&quot;</span>
<span class="n">float_model</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">float_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># deepcopy the model since we need to keep the original model around</span>
<span class="n">model_to_quantize</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">float_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h2>è¯„ä¼°æ¨¡å¼çš„æ¨¡å‹<a class="headerlink" href="#id2" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h2>
<p>å¯¹äºè®­ç»ƒåé‡åŒ–ï¼Œéœ€è¦å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_to_quantize</span><span class="o">.</span><span class="n">eval</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="qconfig-dict">
<h2>ä½¿ç”¨ <code class="docutils literal notranslate"><span class="pre">qconfig_dict</span></code> æŒ‡å®šå¦‚ä½•é‡åŒ–æ¨¡å‹<a class="headerlink" href="#qconfig-dict" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">qconfig_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;&quot;</span> <span class="p">:</span> <span class="n">default_qconfig</span><span class="p">}</span>
</pre></div>
</div>
<p>ä½¿ç”¨ä¸ Eager æ¨¡å¼é‡åŒ–ä¸­ç›¸åŒçš„ <code class="docutils literal notranslate"><span class="pre">qconfig</span></code>, <code class="docutils literal notranslate"><span class="pre">qconfig</span></code> åªæ˜¯ç”¨äºæ¿€æ´»å’Œæƒé‡çš„ observers çš„å‘½åå…ƒç»„ã€‚<code class="docutils literal notranslate"><span class="pre">qconfig_dict</span></code> æ˜¯å…·æœ‰ä»¥ä¸‹é…ç½®çš„å­—å…¸ï¼š</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>qconfig = {
    &quot; : qconfig_global,
    &quot;sub&quot; : qconfig_sub,
    &quot;sub.fc&quot; : qconfig_fc,
    &quot;sub.conv&quot;: None
}
qconfig_dict = {
    # qconfig? means either a valid qconfig or None
    # optional, global config
    &quot;&quot;: qconfig?,
    # optional, used for module and function types
    # could also be split into module_types and function_types if we prefer
    &quot;object_type&quot;: [
        (torch.nn.Conv2d, qconfig?),
        (torch.nn.functional.add, qconfig?),
        ...,
    ],
    # optional, used for module names
    &quot;module_name&quot;: [
        (&quot;foo.bar&quot;, qconfig?)
        ...,
    ],
    # optional, matched in order, first match takes precedence
    &quot;module_name_regex&quot;: [
        (&quot;foo.*bar.*conv[0-9]+&quot;, qconfig?)
        ...,
    ],
    # priority (in increasing order): global, object_type, module_name_regex, module_name
    # qconfig == None means fusion and quantization should be skipped for anything
    # matching the rule

    # **api subject to change**
    # optional: specify the path for standalone modules
    # These modules are symbolically traced and quantized as one unit
    # so that the call to the submodule appears as one call_module
    # node in the forward graph of the GraphModule
    &quot;standalone_module_name&quot;: [
        &quot;submodule.standalone&quot;
    ],
    &quot;standalone_module_class&quot;: [
        StandaloneModuleClass
    ]
}
</pre></div>
</div>
<p>å¯ä»¥åœ¨ <a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/quantization/qconfig.py"><code class="docutils literal notranslate"><span class="pre">qconfig</span></code> æ–‡ä»¶</a> ä¸­æ‰¾åˆ°ä¸ <code class="docutils literal notranslate"><span class="pre">qconfig</span></code> ç›¸å…³çš„å®ç”¨å‡½æ•°ï¼š</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.quantization</span> <span class="kn">import</span> <span class="n">get_default_qconfig</span><span class="p">,</span> <span class="n">quantize_jit</span>

<span class="n">qconfig</span> <span class="o">=</span> <span class="n">get_default_qconfig</span><span class="p">(</span><span class="s2">&quot;fbgemm&quot;</span><span class="p">)</span>
<span class="n">qconfig_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;&quot;</span><span class="p">:</span> <span class="n">qconfig</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h2>ä¸ºé™æ€åè®­ç»ƒé‡åŒ–æ¨¡å‹åšå‡†å¤‡<a class="headerlink" href="#id3" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">torch.quantization.quantize_fx</span> <span class="kn">import</span> <span class="n">prepare_fx</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">prepared_model</span> <span class="o">=</span> <span class="n">prepare_fx</span><span class="p">(</span><span class="n">model_to_quantize</span><span class="p">,</span> <span class="n">qconfig_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">prepare_fx</span></code> å°† BatchNorm æ¨¡å—æŠ˜å åˆ°å‰é¢çš„ Conv2d æ¨¡å—ä¸­ï¼Œå¹¶åœ¨æ¨¡å‹ä¸­çš„é€‚å½“ä½ç½®æ’å…¥ observersã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">prepared_model</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>graph():
    %x : torch.Tensor [#users=1] = placeholder[target=x]
    %activation_post_process_0 : [#users=1] = call_module[target=activation_post_process_0](args = (%x,), kwargs = {})
    %conv1 : [#users=1] = call_module[target=conv1](args = (%activation_post_process_0,), kwargs = {})
    %activation_post_process_1 : [#users=1] = call_module[target=activation_post_process_1](args = (%conv1,), kwargs = {})
    %maxpool : [#users=1] = call_module[target=maxpool](args = (%activation_post_process_1,), kwargs = {})
    %activation_post_process_2 : [#users=2] = call_module[target=activation_post_process_2](args = (%maxpool,), kwargs = {})
    %layer1_0_conv1 : [#users=1] = call_module[target=layer1.0.conv1](args = (%activation_post_process_2,), kwargs = {})
    %activation_post_process_3 : [#users=1] = call_module[target=activation_post_process_3](args = (%layer1_0_conv1,), kwargs = {})
    %layer1_0_conv2 : [#users=1] = call_module[target=layer1.0.conv2](args = (%activation_post_process_3,), kwargs = {})
    %activation_post_process_4 : [#users=1] = call_module[target=activation_post_process_4](args = (%layer1_0_conv2,), kwargs = {})
    %add : [#users=1] = call_function[target=operator.add](args = (%activation_post_process_4, %activation_post_process_2), kwargs = {})
    %layer1_0_relu_1 : [#users=1] = call_module[target=layer1.0.relu](args = (%add,), kwargs = {})
    %activation_post_process_5 : [#users=2] = call_module[target=activation_post_process_5](args = (%layer1_0_relu_1,), kwargs = {})
    %layer1_1_conv1 : [#users=1] = call_module[target=layer1.1.conv1](args = (%activation_post_process_5,), kwargs = {})
    %activation_post_process_6 : [#users=1] = call_module[target=activation_post_process_6](args = (%layer1_1_conv1,), kwargs = {})
    %layer1_1_conv2 : [#users=1] = call_module[target=layer1.1.conv2](args = (%activation_post_process_6,), kwargs = {})
    %activation_post_process_7 : [#users=1] = call_module[target=activation_post_process_7](args = (%layer1_1_conv2,), kwargs = {})
    %add_1 : [#users=1] = call_function[target=operator.add](args = (%activation_post_process_7, %activation_post_process_5), kwargs = {})
    %layer1_1_relu_1 : [#users=1] = call_module[target=layer1.1.relu](args = (%add_1,), kwargs = {})
    %activation_post_process_8 : [#users=2] = call_module[target=activation_post_process_8](args = (%layer1_1_relu_1,), kwargs = {})
    %layer2_0_conv1 : [#users=1] = call_module[target=layer2.0.conv1](args = (%activation_post_process_8,), kwargs = {})
    %activation_post_process_9 : [#users=1] = call_module[target=activation_post_process_9](args = (%layer2_0_conv1,), kwargs = {})
    %layer2_0_conv2 : [#users=1] = call_module[target=layer2.0.conv2](args = (%activation_post_process_9,), kwargs = {})
    %activation_post_process_10 : [#users=1] = call_module[target=activation_post_process_10](args = (%layer2_0_conv2,), kwargs = {})
    %layer2_0_downsample_0 : [#users=1] = call_module[target=layer2.0.downsample.0](args = (%activation_post_process_8,), kwargs = {})
    %activation_post_process_11 : [#users=1] = call_module[target=activation_post_process_11](args = (%layer2_0_downsample_0,), kwargs = {})
    %add_2 : [#users=1] = call_function[target=operator.add](args = (%activation_post_process_10, %activation_post_process_11), kwargs = {})
    %layer2_0_relu_1 : [#users=1] = call_module[target=layer2.0.relu](args = (%add_2,), kwargs = {})
    %activation_post_process_12 : [#users=2] = call_module[target=activation_post_process_12](args = (%layer2_0_relu_1,), kwargs = {})
    %layer2_1_conv1 : [#users=1] = call_module[target=layer2.1.conv1](args = (%activation_post_process_12,), kwargs = {})
    %activation_post_process_13 : [#users=1] = call_module[target=activation_post_process_13](args = (%layer2_1_conv1,), kwargs = {})
    %layer2_1_conv2 : [#users=1] = call_module[target=layer2.1.conv2](args = (%activation_post_process_13,), kwargs = {})
    %activation_post_process_14 : [#users=1] = call_module[target=activation_post_process_14](args = (%layer2_1_conv2,), kwargs = {})
    %add_3 : [#users=1] = call_function[target=operator.add](args = (%activation_post_process_14, %activation_post_process_12), kwargs = {})
    %layer2_1_relu_1 : [#users=1] = call_module[target=layer2.1.relu](args = (%add_3,), kwargs = {})
    %activation_post_process_15 : [#users=2] = call_module[target=activation_post_process_15](args = (%layer2_1_relu_1,), kwargs = {})
    %layer3_0_conv1 : [#users=1] = call_module[target=layer3.0.conv1](args = (%activation_post_process_15,), kwargs = {})
    %activation_post_process_16 : [#users=1] = call_module[target=activation_post_process_16](args = (%layer3_0_conv1,), kwargs = {})
    %layer3_0_conv2 : [#users=1] = call_module[target=layer3.0.conv2](args = (%activation_post_process_16,), kwargs = {})
    %activation_post_process_17 : [#users=1] = call_module[target=activation_post_process_17](args = (%layer3_0_conv2,), kwargs = {})
    %layer3_0_downsample_0 : [#users=1] = call_module[target=layer3.0.downsample.0](args = (%activation_post_process_15,), kwargs = {})
    %activation_post_process_18 : [#users=1] = call_module[target=activation_post_process_18](args = (%layer3_0_downsample_0,), kwargs = {})
    %add_4 : [#users=1] = call_function[target=operator.add](args = (%activation_post_process_17, %activation_post_process_18), kwargs = {})
    %layer3_0_relu_1 : [#users=1] = call_module[target=layer3.0.relu](args = (%add_4,), kwargs = {})
    %activation_post_process_19 : [#users=2] = call_module[target=activation_post_process_19](args = (%layer3_0_relu_1,), kwargs = {})
    %layer3_1_conv1 : [#users=1] = call_module[target=layer3.1.conv1](args = (%activation_post_process_19,), kwargs = {})
    %activation_post_process_20 : [#users=1] = call_module[target=activation_post_process_20](args = (%layer3_1_conv1,), kwargs = {})
    %layer3_1_conv2 : [#users=1] = call_module[target=layer3.1.conv2](args = (%activation_post_process_20,), kwargs = {})
    %activation_post_process_21 : [#users=1] = call_module[target=activation_post_process_21](args = (%layer3_1_conv2,), kwargs = {})
    %add_5 : [#users=1] = call_function[target=operator.add](args = (%activation_post_process_21, %activation_post_process_19), kwargs = {})
    %layer3_1_relu_1 : [#users=1] = call_module[target=layer3.1.relu](args = (%add_5,), kwargs = {})
    %activation_post_process_22 : [#users=2] = call_module[target=activation_post_process_22](args = (%layer3_1_relu_1,), kwargs = {})
    %layer4_0_conv1 : [#users=1] = call_module[target=layer4.0.conv1](args = (%activation_post_process_22,), kwargs = {})
    %activation_post_process_23 : [#users=1] = call_module[target=activation_post_process_23](args = (%layer4_0_conv1,), kwargs = {})
    %layer4_0_conv2 : [#users=1] = call_module[target=layer4.0.conv2](args = (%activation_post_process_23,), kwargs = {})
    %activation_post_process_24 : [#users=1] = call_module[target=activation_post_process_24](args = (%layer4_0_conv2,), kwargs = {})
    %layer4_0_downsample_0 : [#users=1] = call_module[target=layer4.0.downsample.0](args = (%activation_post_process_22,), kwargs = {})
    %activation_post_process_25 : [#users=1] = call_module[target=activation_post_process_25](args = (%layer4_0_downsample_0,), kwargs = {})
    %add_6 : [#users=1] = call_function[target=operator.add](args = (%activation_post_process_24, %activation_post_process_25), kwargs = {})
    %layer4_0_relu_1 : [#users=1] = call_module[target=layer4.0.relu](args = (%add_6,), kwargs = {})
    %activation_post_process_26 : [#users=2] = call_module[target=activation_post_process_26](args = (%layer4_0_relu_1,), kwargs = {})
    %layer4_1_conv1 : [#users=1] = call_module[target=layer4.1.conv1](args = (%activation_post_process_26,), kwargs = {})
    %activation_post_process_27 : [#users=1] = call_module[target=activation_post_process_27](args = (%layer4_1_conv1,), kwargs = {})
    %layer4_1_conv2 : [#users=1] = call_module[target=layer4.1.conv2](args = (%activation_post_process_27,), kwargs = {})
    %activation_post_process_28 : [#users=1] = call_module[target=activation_post_process_28](args = (%layer4_1_conv2,), kwargs = {})
    %add_7 : [#users=1] = call_function[target=operator.add](args = (%activation_post_process_28, %activation_post_process_26), kwargs = {})
    %layer4_1_relu_1 : [#users=1] = call_module[target=layer4.1.relu](args = (%add_7,), kwargs = {})
    %activation_post_process_29 : [#users=1] = call_module[target=activation_post_process_29](args = (%layer4_1_relu_1,), kwargs = {})
    %avgpool : [#users=1] = call_module[target=avgpool](args = (%activation_post_process_29,), kwargs = {})
    %activation_post_process_30 : [#users=1] = call_module[target=activation_post_process_30](args = (%avgpool,), kwargs = {})
    %flatten : [#users=1] = call_function[target=torch.flatten](args = (%activation_post_process_30, 1), kwargs = {})
    %activation_post_process_31 : [#users=1] = call_module[target=activation_post_process_31](args = (%flatten,), kwargs = {})
    %fc : [#users=1] = call_module[target=fc](args = (%activation_post_process_31,), kwargs = {})
    %activation_post_process_32 : [#users=1] = call_module[target=activation_post_process_32](args = (%fc,), kwargs = {})
    return activation_post_process_32
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h2>æ ¡å‡†<a class="headerlink" href="#id4" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h2>
<p>å°† observers æ’å…¥æ¨¡å‹åï¼Œè¿è¡Œæ ¡å‡†å‡½æ•°ã€‚æ ¡å‡†çš„ç›®çš„å°±æ˜¯é€šè¿‡ä¸€äº›æ ·æœ¬è¿è¡Œä»£è¡¨æ€§çš„å·¥ä½œè´Ÿè½½ï¼ˆä¾‹å¦‚æ ·æœ¬çš„è®­ç»ƒæ•°æ®é›†ï¼‰ä»¥ä¾¿ observers åœ¨æ¨¡å‹ä¸­èƒ½å¤Ÿè§‚æµ‹åˆ°å¼ é‡çš„ç»Ÿè®¡æ•°æ®ï¼Œä»¥åä½¿ç”¨è¿™äº›ä¿¡æ¯æ¥è®¡ç®—é‡åŒ–å‚æ•°ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">calibrate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">image</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="n">samples</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="n">k</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="n">calibrate</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">,</span> <span class="n">trainset</span><span class="p">)</span>  <span class="c1"># run calibration on sample data</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id5">
<h2>å°†æ¨¡å‹è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹<a class="headerlink" href="#id5" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">convert_fx</span></code> é‡‡ç”¨æ ¡å‡†æ¨¡å‹å¹¶äº§ç”Ÿé‡åŒ–æ¨¡å‹ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.quantization.quantize_fx</span> <span class="kn">import</span> <span class="n">convert_fx</span>

<span class="n">quantized_model</span> <span class="o">=</span> <span class="n">convert_fx</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">quantized_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GraphModule(
  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.03267836198210716, zero_point=0, padding=(3, 3))
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Module(
    (0): Module(
      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.019193191081285477, zero_point=0, padding=(1, 1))
      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.051562923938035965, zero_point=75, padding=(1, 1))
    )
    (1): Module(
      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.019093887880444527, zero_point=0, padding=(1, 1))
      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.06979087740182877, zero_point=78, padding=(1, 1))
    )
  )
  (layer2): Module(
    (0): Module(
      (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.01557458657771349, zero_point=0, padding=(1, 1))
      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.050476107746362686, zero_point=68, padding=(1, 1))
      (downsample): Module(
        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.039443813264369965, zero_point=60)
      )
    )
    (1): Module(
      (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.016193654388189316, zero_point=0, padding=(1, 1))
      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.05214320868253708, zero_point=68, padding=(1, 1))
    )
  )
  (layer3): Module(
    (0): Module(
      (conv1): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.018163194879889488, zero_point=0, padding=(1, 1))
      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.05316956341266632, zero_point=51, padding=(1, 1))
      (downsample): Module(
        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.01836947724223137, zero_point=107)
      )
    )
    (1): Module(
      (conv1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.013543782755732536, zero_point=0, padding=(1, 1))
      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.048523254692554474, zero_point=71, padding=(1, 1))
    )
  )
  (layer4): Module(
    (0): Module(
      (conv1): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.014485283754765987, zero_point=0, padding=(1, 1))
      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.0517863854765892, zero_point=64, padding=(1, 1))
      (downsample): Module(
        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.04331441596150398, zero_point=58)
      )
    )
    (1): Module(
      (conv1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.021167000755667686, zero_point=0, padding=(1, 1))
      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.22766999900341034, zero_point=45, padding=(1, 1))
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): QuantizedLinear(in_features=512, out_features=1000, scale=0.27226582169532776, zero_point=35, qscheme=torch.per_channel_affine)
)



def forward(self, x : torch.Tensor):
    conv1_input_scale_0 = self.conv1_input_scale_0
    conv1_input_zero_point_0 = self.conv1_input_zero_point_0
    quantize_per_tensor = torch.quantize_per_tensor(x, conv1_input_scale_0, conv1_input_zero_point_0, torch.quint8);  x = conv1_input_scale_0 = conv1_input_zero_point_0 = None
    conv1 = self.conv1(quantize_per_tensor);  quantize_per_tensor = None
    maxpool = self.maxpool(conv1);  conv1 = None
    layer1_0_conv1 = getattr(self.layer1, &quot;0&quot;).conv1(maxpool)
    layer1_0_conv2 = getattr(self.layer1, &quot;0&quot;).conv2(layer1_0_conv1);  layer1_0_conv1 = None
    layer1_0_relu_scale_0 = self.layer1_0_relu_scale_0
    layer1_0_relu_zero_point_0 = self.layer1_0_relu_zero_point_0
    add_relu = torch.ops.quantized.add_relu(layer1_0_conv2, maxpool, layer1_0_relu_scale_0, layer1_0_relu_zero_point_0);  layer1_0_conv2 = maxpool = layer1_0_relu_scale_0 = layer1_0_relu_zero_point_0 = None
    layer1_1_conv1 = getattr(self.layer1, &quot;1&quot;).conv1(add_relu)
    layer1_1_conv2 = getattr(self.layer1, &quot;1&quot;).conv2(layer1_1_conv1);  layer1_1_conv1 = None
    layer1_1_relu_scale_0 = self.layer1_1_relu_scale_0
    layer1_1_relu_zero_point_0 = self.layer1_1_relu_zero_point_0
    add_relu_1 = torch.ops.quantized.add_relu(layer1_1_conv2, add_relu, layer1_1_relu_scale_0, layer1_1_relu_zero_point_0);  layer1_1_conv2 = add_relu = layer1_1_relu_scale_0 = layer1_1_relu_zero_point_0 = None
    layer2_0_conv1 = getattr(self.layer2, &quot;0&quot;).conv1(add_relu_1)
    layer2_0_conv2 = getattr(self.layer2, &quot;0&quot;).conv2(layer2_0_conv1);  layer2_0_conv1 = None
    layer2_0_downsample_0 = getattr(getattr(self.layer2, &quot;0&quot;).downsample, &quot;0&quot;)(add_relu_1);  add_relu_1 = None
    layer2_0_relu_scale_0 = self.layer2_0_relu_scale_0
    layer2_0_relu_zero_point_0 = self.layer2_0_relu_zero_point_0
    add_relu_2 = torch.ops.quantized.add_relu(layer2_0_conv2, layer2_0_downsample_0, layer2_0_relu_scale_0, layer2_0_relu_zero_point_0);  layer2_0_conv2 = layer2_0_downsample_0 = layer2_0_relu_scale_0 = layer2_0_relu_zero_point_0 = None
    layer2_1_conv1 = getattr(self.layer2, &quot;1&quot;).conv1(add_relu_2)
    layer2_1_conv2 = getattr(self.layer2, &quot;1&quot;).conv2(layer2_1_conv1);  layer2_1_conv1 = None
    layer2_1_relu_scale_0 = self.layer2_1_relu_scale_0
    layer2_1_relu_zero_point_0 = self.layer2_1_relu_zero_point_0
    add_relu_3 = torch.ops.quantized.add_relu(layer2_1_conv2, add_relu_2, layer2_1_relu_scale_0, layer2_1_relu_zero_point_0);  layer2_1_conv2 = add_relu_2 = layer2_1_relu_scale_0 = layer2_1_relu_zero_point_0 = None
    layer3_0_conv1 = getattr(self.layer3, &quot;0&quot;).conv1(add_relu_3)
    layer3_0_conv2 = getattr(self.layer3, &quot;0&quot;).conv2(layer3_0_conv1);  layer3_0_conv1 = None
    layer3_0_downsample_0 = getattr(getattr(self.layer3, &quot;0&quot;).downsample, &quot;0&quot;)(add_relu_3);  add_relu_3 = None
    layer3_0_relu_scale_0 = self.layer3_0_relu_scale_0
    layer3_0_relu_zero_point_0 = self.layer3_0_relu_zero_point_0
    add_relu_4 = torch.ops.quantized.add_relu(layer3_0_conv2, layer3_0_downsample_0, layer3_0_relu_scale_0, layer3_0_relu_zero_point_0);  layer3_0_conv2 = layer3_0_downsample_0 = layer3_0_relu_scale_0 = layer3_0_relu_zero_point_0 = None
    layer3_1_conv1 = getattr(self.layer3, &quot;1&quot;).conv1(add_relu_4)
    layer3_1_conv2 = getattr(self.layer3, &quot;1&quot;).conv2(layer3_1_conv1);  layer3_1_conv1 = None
    layer3_1_relu_scale_0 = self.layer3_1_relu_scale_0
    layer3_1_relu_zero_point_0 = self.layer3_1_relu_zero_point_0
    add_relu_5 = torch.ops.quantized.add_relu(layer3_1_conv2, add_relu_4, layer3_1_relu_scale_0, layer3_1_relu_zero_point_0);  layer3_1_conv2 = add_relu_4 = layer3_1_relu_scale_0 = layer3_1_relu_zero_point_0 = None
    layer4_0_conv1 = getattr(self.layer4, &quot;0&quot;).conv1(add_relu_5)
    layer4_0_conv2 = getattr(self.layer4, &quot;0&quot;).conv2(layer4_0_conv1);  layer4_0_conv1 = None
    layer4_0_downsample_0 = getattr(getattr(self.layer4, &quot;0&quot;).downsample, &quot;0&quot;)(add_relu_5);  add_relu_5 = None
    layer4_0_relu_scale_0 = self.layer4_0_relu_scale_0
    layer4_0_relu_zero_point_0 = self.layer4_0_relu_zero_point_0
    add_relu_6 = torch.ops.quantized.add_relu(layer4_0_conv2, layer4_0_downsample_0, layer4_0_relu_scale_0, layer4_0_relu_zero_point_0);  layer4_0_conv2 = layer4_0_downsample_0 = layer4_0_relu_scale_0 = layer4_0_relu_zero_point_0 = None
    layer4_1_conv1 = getattr(self.layer4, &quot;1&quot;).conv1(add_relu_6)
    layer4_1_conv2 = getattr(self.layer4, &quot;1&quot;).conv2(layer4_1_conv1);  layer4_1_conv1 = None
    layer4_1_relu_scale_0 = self.layer4_1_relu_scale_0
    layer4_1_relu_zero_point_0 = self.layer4_1_relu_zero_point_0
    add_relu_7 = torch.ops.quantized.add_relu(layer4_1_conv2, add_relu_6, layer4_1_relu_scale_0, layer4_1_relu_zero_point_0);  layer4_1_conv2 = add_relu_6 = layer4_1_relu_scale_0 = layer4_1_relu_zero_point_0 = None
    avgpool = self.avgpool(add_relu_7);  add_relu_7 = None
    flatten = torch.flatten(avgpool, 1);  avgpool = None
    fc = self.fc(flatten);  flatten = None
    dequantize_14 = fc.dequantize();  fc = None
    return dequantize_14
    
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h2>è¯„ä¼°<a class="headerlink" href="#id6" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h2>
<p>ç°åœ¨å¯ä»¥æ‰“å°é‡åŒ–æ¨¡å‹çš„å¤§å°å’Œç²¾åº¦ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_book.contrib.helper</span> <span class="kn">import</span> <span class="n">evaluate</span><span class="p">,</span> <span class="n">print_size_of_model</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of model before quantization&quot;</span><span class="p">)</span>
<span class="n">print_size_of_model</span><span class="p">(</span><span class="n">float_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of model after quantization&quot;</span><span class="p">)</span>
<span class="n">print_size_of_model</span><span class="p">(</span><span class="n">quantized_model</span><span class="p">)</span>
<span class="n">top1</span><span class="p">,</span> <span class="n">top5</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">quantized_model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">valset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Size of model before quantization
æ¨¡å‹å¤§å°(MB)ï¼š46.873073 MB
Size of model after quantization
æ¨¡å‹å¤§å°(MB)ï¼š11.853109 MB
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[before serilaization] Evaluation accuracy on test dataset: </span><span class="si">{</span><span class="n">top1</span><span class="o">.</span><span class="n">avg</span><span class="si">:</span><span class="s2">2.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">top5</span><span class="o">.</span><span class="n">avg</span><span class="si">:</span><span class="s2">2.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[before serilaization] Evaluation accuracy on test dataset: 69.37, 88.89
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fx_graph_mode_model_file_path</span> <span class="o">=</span> <span class="n">saved_model_dir</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_fx_graph_mode_quantized.pth&quot;</span>

<span class="c1"># this does not run due to some erros loading convrelu module:</span>
<span class="c1"># ModuleAttributeError: &#39;ConvReLU2d&#39; object has no attribute &#39;_modules&#39;</span>
<span class="c1"># save the whole model directly</span>
<span class="c1"># torch.save(quantized_model, fx_graph_mode_model_file_path)</span>
<span class="c1"># loaded_quantized_model = torch.load(fx_graph_mode_model_file_path)</span>

<span class="c1"># save with state_dict</span>
<span class="c1"># torch.save(quantized_model.state_dict(), fx_graph_mode_model_file_path)</span>
<span class="c1"># import copy</span>
<span class="c1"># model_to_quantize = copy.deepcopy(float_model)</span>
<span class="c1"># prepared_model = prepare_fx(model_to_quantize, {&quot;&quot;: qconfig})</span>
<span class="c1"># loaded_quantized_model = convert_fx(prepared_model)</span>
<span class="c1"># loaded_quantized_model.load_state_dict(torch.load(fx_graph_mode_model_file_path))</span>

<span class="c1"># save with script</span>
<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">quantized_model</span><span class="p">),</span> <span class="n">fx_graph_mode_model_file_path</span><span class="p">)</span>
<span class="n">loaded_quantized_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fx_graph_mode_model_file_path</span><span class="p">)</span>

<span class="n">top1</span><span class="p">,</span> <span class="n">top5</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">loaded_quantized_model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">valset</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[after serialization/deserialization] Evaluation accuracy on test dataset: </span><span class="si">{</span><span class="n">top1</span><span class="o">.</span><span class="n">avg</span><span class="si">:</span><span class="s2">2.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">top5</span><span class="o">.</span><span class="n">avg</span><span class="si">:</span><span class="s2">2.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[after serialization/deserialization] Evaluation accuracy on test dataset: 69.37, 88.89
</pre></div>
</div>
</div>
</div>
<p>å¦‚æœå¸Œæœ›è·å¾—æ›´å¥½çš„ç²¾åº¦æˆ–æ€§èƒ½ï¼Œè¯·å°è¯•æ›´æ”¹ <code class="docutils literal notranslate"><span class="pre">qconfig_dict</span></code>ã€‚</p>
</section>
<section id="id7">
<h2>è°ƒè¯•é‡åŒ–æ¨¡å‹<a class="headerlink" href="#id7" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h2>
<p>è¿˜å¯ä»¥æ‰“å°é‡åŒ–çš„ un-quantized conv çš„æƒé‡æ¥æŸ¥çœ‹åŒºåˆ«ï¼Œé¦–å…ˆæ˜¾å¼åœ°è°ƒç”¨ <code class="docutils literal notranslate"><span class="pre">fuse</span></code> æ¥èåˆæ¨¡å‹ä¸­çš„ conv å’Œ bnï¼šæ³¨æ„ï¼Œ<code class="docutils literal notranslate"><span class="pre">fuse_fx</span></code> åªåœ¨ <code class="docutils literal notranslate"><span class="pre">eval</span></code> æ¨¡å¼ä¸‹å·¥ä½œã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.quantization.quantize_fx</span> <span class="kn">import</span> <span class="n">fuse_fx</span>

<span class="n">fused</span> <span class="o">=</span> <span class="n">fuse_fx</span><span class="p">(</span><span class="n">float_model</span><span class="p">)</span>

<span class="n">conv1_weight_after_fuse</span> <span class="o">=</span> <span class="n">fused</span><span class="o">.</span><span class="n">conv1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">conv1_weight_after_quant</span> <span class="o">=</span> <span class="n">quantized_model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">()</span><span class="o">.</span><span class="n">dequantize</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">conv1_weight_after_fuse</span> <span class="o">-</span> <span class="n">conv1_weight_after_quant</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.0007, grad_fn=&lt;MaxBackward1&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="eager">
<h2>åŸºçº¿æµ®ç‚¹æ¨¡å‹å’Œ Eager æ¨¡å¼é‡åŒ–çš„æ¯”è¾ƒ<a class="headerlink" href="#eager" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scripted_float_model_file</span> <span class="o">=</span> <span class="s2">&quot;resnet18_scripted.pth&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of baseline model&quot;</span><span class="p">)</span>
<span class="n">print_size_of_model</span><span class="p">(</span><span class="n">float_model</span><span class="p">)</span>

<span class="n">top1</span><span class="p">,</span> <span class="n">top5</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">float_model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">valset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Baseline Float Model Evaluation accuracy: </span><span class="si">%2.2f</span><span class="s2">, </span><span class="si">%2.2f</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">top1</span><span class="o">.</span><span class="n">avg</span><span class="p">,</span> <span class="n">top5</span><span class="o">.</span><span class="n">avg</span><span class="p">))</span>
<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">float_model</span><span class="p">),</span> <span class="n">saved_model_dir</span> <span class="o">+</span> <span class="n">scripted_float_model_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Size of baseline model
æ¨¡å‹å¤§å°(MB)ï¼š46.874273 MB
Baseline Float Model Evaluation accuracy: 69.76, 89.08
</pre></div>
</div>
</div>
</div>
<p>åœ¨æœ¬èŠ‚ä¸­ï¼Œå°†é‡åŒ–æ¨¡å‹ä¸ FX Graph æ¨¡å¼çš„é‡åŒ–æ¨¡å‹ä¸åœ¨ Eager æ¨¡å¼ä¸‹é‡åŒ–çš„æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚FX Graph æ¨¡å¼å’Œ Eager æ¨¡å¼äº§ç”Ÿçš„é‡åŒ–æ¨¡å‹éå¸¸ç›¸ä¼¼ï¼Œå› æ­¤æœŸæœ›ç²¾åº¦å’Œ speedup ä¹Ÿå¾ˆç›¸ä¼¼ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of Fx graph mode quantized model&quot;</span><span class="p">)</span>
<span class="n">print_size_of_model</span><span class="p">(</span><span class="n">quantized_model</span><span class="p">)</span>
<span class="n">top1</span><span class="p">,</span> <span class="n">top5</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">quantized_model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">valset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FX graph mode quantized model Evaluation accuracy on test dataset: </span><span class="si">%2.2f</span><span class="s2">, </span><span class="si">%2.2f</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">top1</span><span class="o">.</span><span class="n">avg</span><span class="p">,</span> <span class="n">top5</span><span class="o">.</span><span class="n">avg</span><span class="p">))</span>

<span class="kn">from</span> <span class="nn">torchvision.models.quantization.resnet</span> <span class="kn">import</span> <span class="n">resnet18</span>
<span class="n">eager_quantized_model</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">quantize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of eager mode quantized model&quot;</span><span class="p">)</span>
<span class="n">eager_quantized_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">eager_quantized_model</span><span class="p">)</span>
<span class="n">print_size_of_model</span><span class="p">(</span><span class="n">eager_quantized_model</span><span class="p">)</span>
<span class="n">top1</span><span class="p">,</span> <span class="n">top5</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">eager_quantized_model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">valset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;eager mode quantized model Evaluation accuracy on test dataset: </span><span class="si">%2.2f</span><span class="s2">, </span><span class="si">%2.2f</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">top1</span><span class="o">.</span><span class="n">avg</span><span class="p">,</span> <span class="n">top5</span><span class="o">.</span><span class="n">avg</span><span class="p">))</span>
<span class="n">eager_mode_model_file</span> <span class="o">=</span> <span class="s2">&quot;resnet18_eager_mode_quantized.pth&quot;</span>
<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">eager_quantized_model</span><span class="p">,</span> <span class="n">saved_model_dir</span> <span class="o">+</span> <span class="n">eager_mode_model_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Size of Fx graph mode quantized model
æ¨¡å‹å¤§å°(MB)ï¼š11.855297 MB
FX graph mode quantized model Evaluation accuracy on test dataset: 69.37, 88.89
Size of eager mode quantized model
æ¨¡å‹å¤§å°(MB)ï¼š11.850395 MB
eager mode quantized model Evaluation accuracy on test dataset: 69.50, 88.88
</pre></div>
</div>
</div>
</div>
<p>å¯ä»¥çœ‹åˆ° FX Graph æ¨¡å¼å’Œ Eager æ¨¡å¼é‡åŒ–æ¨¡å‹çš„æ¨¡å‹å¤§å°å’Œç²¾åº¦æ˜¯éå¸¸ç›¸ä¼¼çš„ã€‚</p>
<p>åœ¨ AIBench ä¸­è¿è¡Œæ¨¡å‹ï¼ˆå•çº¿ç¨‹ï¼‰ä¼šå¾—åˆ°å¦‚ä¸‹ç»“æœï¼š</p>
<div class="highlight-log notranslate"><div class="highlight"><pre><span></span>Scripted Float Model:
Self CPU time total: 192.48ms

Scripted Eager Mode Quantized Model:
Self CPU time total: 50.76ms

Scripted FX Graph Mode Quantized Model:
Self CPU time total: 50.63ms
</pre></div>
</div>
<p>å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äº resnet18, FX Graph æ¨¡å¼å’Œ Eager æ¨¡å¼é‡åŒ–æ¨¡å‹éƒ½æ¯”æµ®ç‚¹æ¨¡å‹è·å¾—äº†ç›¸ä¼¼çš„é€Ÿåº¦ï¼Œå¤§çº¦æ¯”æµ®ç‚¹æ¨¡å‹å¿« 2-4 å€ã€‚ä½†æ˜¯æµ®ç‚¹æ¨¡å‹ä¸Šçš„å®é™…åŠ é€Ÿå¯èƒ½ä¼šå› æ¨¡å‹ã€è®¾å¤‡ã€æ„å»ºã€è¾“å…¥æ‰¹å¤§å°ã€çº¿ç¨‹ç­‰è€Œä¸åŒã€‚</p>
</section>
</section>

<div class="section">
   
</div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="ä¸Šä¸€é¡µ é¡µ">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">ä¸Šä¸€é¡µ</p>
            <p class="prev-next-title">é‡åŒ–ç®€ä»‹</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../openmmlab/index.html" title="ä¸‹ä¸€é¡µ é¡µ">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">ä¸‹ä¸€é¡µ</p>
        <p class="prev-next-title">MMDetection</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By xinetzone<br/>
  
      &copy; Copyright 2021, xinetzone.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>